{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb3b1e-afbf-4d92-81b2-b76274d8a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import boto3\n",
    "import pymongo \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import cabutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1959d68-9d55-484b-b308-7d8725690867",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"font.size\"] = 18\n",
    "rcParams[\"figure.titlesize\"] = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c021a9-a6aa-40c4-a5ae-660dc08d029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "projName = \"mlve\"\n",
    "experiment = \"nsd\"\n",
    "experimentName = f\"{experiment}-surface-normals\"\n",
    "S3_BUCKET_NAME = \"mlve-v1\"\n",
    "\n",
    "attention_check = \"attentionCheck\"\n",
    "batch_idx = \"batchIdx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514bb29-f77a-49e9-a784-244ace372e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = cabutils.get_db_connection()\n",
    "db = conn[projName + \"_outputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a040dafa-f208-41d5-8673-f2107762b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(db.list_collection_names())\n",
    "names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570ca99-80c7-47b6-91dd-330962f19875",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e47218-cbc3-4afd-bb7a-c04769f386ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_df(iterName=None):\n",
    "        results = []\n",
    "        cursor = col.find({})\n",
    "        for document in tqdm(cursor):\n",
    "            results.append(document)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cedfe-5122-451a-94e7-e4952bd9c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in tqdm(names):\n",
    "    col = db[col_name]\n",
    "    summaries[col_name] = {}\n",
    "    print(\"Getting summary data for \", col_name)\n",
    "    \n",
    "    if os.path.exists(f\"datasets/{col_name}.csv\"):\n",
    "        df = pd.read_csv(f\"datasets/{col_name}.csv\")\n",
    "    else:\n",
    "        df = results_to_df() # drop non-experiment trials\n",
    "        df.to_csv(f\"datasets/{col_name}.csv\")\n",
    "    \n",
    "    get_trial_key = lambda x: [key for key in x if \"batch\" in key][0]\n",
    "    \n",
    "    total_records = len(df)\n",
    "    n_participants = len(df[\"userID\"].dropna().unique())\n",
    "    iteration_names = df[\"iterationName\"].unique()\n",
    "\n",
    "    get_batch_key = lambda x: [key for key in x if \"batch\" in key][0]\n",
    "    batch_key = get_batch_key(df.columns)\n",
    "    n_batches = len(df[batch_key].dropna().unique())\n",
    "    \n",
    "    print(f\"Total Records: {total_records}, n_participants: {n_participants}, n_points: {n_batches}, iterations: {len(iteration_names)}\")\n",
    "    \n",
    "    summaries[col_name][\"n_participants\"] = n_participants\n",
    "    summaries[col_name][\"n_points\"] = n_batches\n",
    "    summaries[col_name][\"total_records\"] = total_records\n",
    "    summaries[col_name][\"n_iterations\"] = len(iteration_names)\n",
    "    summaries[col_name][\"iteration_names\"] = iteration_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bed4e-286b-4f94-8661-f3dcceacc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summaries = summaries\n",
    "\n",
    "summaries = {}\n",
    "for key in all_summaries:\n",
    "    if \"object-loc\" not in key:\n",
    "        summaries[key] = all_summaries[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c08a1-e1a6-4328-8d30-feb1586f6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afb596-d027-4148-96e6-be36482788b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b79f8-1f33-460b-96ad-13f5dda35147",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_first = {\"n_participants\": {}, \"n_points\": {}, \"n_iterations\": {}, \"total_records\": {}, \"iteration_names\": {}}\n",
    "for dataset in summaries:\n",
    "    for stat in summaries[dataset]:\n",
    "        stat_first[stat][dataset] = summaries[dataset][stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9934e5-e330-4751-b23d-51054bb64cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df = pd.DataFrame(stat_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711a7ac-dd0e-468a-ac95-79d762969f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df.to_csv(\"stat_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e86aa-a7c9-4e98-b49d-484e069f0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789900e7-b53e-4a0d-9983-c1dd2ee0f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_df[\"n_participants\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb7af6-3c5d-4453-a206-21d6ec21ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72688f0d-600d-4aa7-8d8e-d2b2ec760f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_attention_check_fails(df, key=\"correct\", threshold=0.5, remove_failures=True, remove_attention_trials=True):\n",
    "    att_key = lambda x: [k for k in x if \"attention\" in k][0]\n",
    "    attention_key = att_key(df.columns)\n",
    "    att_checks = df.loc[df[attention_key] == True]\n",
    "    failed_checks = att_checks.groupby(\"userID\")[key].mean() < threshold\n",
    "    participants_failed = [failed_checks.keys()[i] for i in range(len(failed_checks)) if failed_checks[i]]\n",
    "    if remove_failures:\n",
    "        if len(participants_failed) == 0:\n",
    "            print(\"No one failed any attention checks!\")\n",
    "        else:   \n",
    "            df = df[~df[\"userID\"].isin(participants_failed)]\n",
    "        \n",
    "    if remove_attention_trials:\n",
    "        df = df[df[attention_key] == False]\n",
    "            \n",
    "    return df\n",
    "\n",
    "def str_to_float_array(str_arr):\n",
    "    if type(str_arr) == list:\n",
    "        return str_arr\n",
    "    \n",
    "    if str_arr == np.nan or str_arr == \"nan\" or str_arr == float(\"nan\") or not str_arr:\n",
    "        return []\n",
    "\n",
    "    arr = []\n",
    "    str_arr = str_arr.strip(\"[]\").split(\",\")\n",
    "    for st in str_arr:\n",
    "        try:\n",
    "            arr.append(float(st))\n",
    "        except:\n",
    "            return []\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531dcbdb-3a42-40b9-a2ad-1ef464628a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col_name in names:\n",
    "    path = f\"datasets/{col_name}.csv\"\n",
    "    if \"depth\" in path or \"segmentation\" in path:\n",
    "        \n",
    "        print(col_name)\n",
    "\n",
    "        if col_name == \"nsd-depth-estimation-pilot\" or col_name == \"nsd-depth-estimation-split-half\":\n",
    "            continue\n",
    "            \n",
    "        accuracy_key = \"correct\"\n",
    "        target_key = \"userID\"\n",
    "        \n",
    "        if col_name == \"nsd-segmentation\" or col_name == \"tdw-segmentation\":\n",
    "            accuracy_key = \"segmentation_correct\"\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        if col_name != \"tdw-segmentation\":\n",
    "            df = filter_attention_check_fails(df, accuracy_key)\n",
    "        df = df[df[\"trial_type\"].str.contains(\"task\")]\n",
    "        \n",
    "        fig = plotting.plot_accuracy(df, col_name, accuracy_key=accuracy_key, target_key=target_key)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        fig = plotting.plot_accuracy(df, col_name, accuracy_key=accuracy_key, errorbar=None, target_key=\"stimulus\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        if df[\"response\"].iloc[0] is np.nan:\n",
    "            response_key = \"segmentation_response\"\n",
    "        else:\n",
    "            response_key = \"response\"\n",
    "            \n",
    "        df[response_key] = pd.to_numeric(df[response_key])\n",
    "        \n",
    "        fig = plotting.plot_split_half(df, response_key, col_name)\n",
    "        print(\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f36ad-286f-4af2-a6e2-b53ef5e5e2af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col_name in names:\n",
    "    path = f\"datasets/{col_name}.csv\"\n",
    "    if \"surface-normals\" in path:\n",
    "        if \"hypersim_surface-normals\" in path:\n",
    "            continue\n",
    "        \n",
    "        print(path)\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        df = df.dropna(axis=0, subset=\"indicatorFinalDirection\")\n",
    "        get_attention_key = lambda x: [k for k in x if \"attention\" in k][0]\n",
    "        attention_key = get_attention_key(df.columns)\n",
    "        get_duplicate_key = lambda x: [k for k in x if \"duplicate\" in k][0]\n",
    "        duplicate_key = get_duplicate_key(df.columns)\n",
    "\n",
    "        df = df[df[duplicate_key] == False]\n",
    "        df = df[df[attention_key] == False]\n",
    "        \n",
    "        df[\"indicatorFinalDirection\"] = df[\"indicatorFinalDirection\"].apply(str_to_float_array)\n",
    "        if \"nsd\" not in col_name:\n",
    "            df[\"trueArrowDirection\"] = df[\"trueArrowDirection\"].apply(str_to_float_array)\n",
    "            \n",
    "        plotting.plot_surface_normal_split_half(df, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6216f49c-bc28-472d-b917-ba078d685c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col_name in names:\n",
    "    path = f\"datasets/{col_name}.csv\"\n",
    "    if \"surface-normals\" in path:\n",
    "        if \"hypersim_surface-normals\" in path:\n",
    "            continue\n",
    "        \n",
    "        print(path)\n",
    "        \n",
    "        df = pd.read_csv(path)\n",
    "        df = df.dropna(axis=0, subset=\"indicatorFinalDirection\")\n",
    "        get_attention_key = lambda x: [k for k in x if \"attention\" in k][0]\n",
    "        attention_key = get_attention_key(df.columns)\n",
    "        get_duplicate_key = lambda x: [k for k in x if \"duplicate\" in k][0]\n",
    "        duplicate_key = get_duplicate_key(df.columns)\n",
    "\n",
    "        df = df[df[duplicate_key] == False]\n",
    "        df = df[df[attention_key] == False]\n",
    "        \n",
    "        df[\"indicatorFinalDirection\"] = df[\"indicatorFinalDirection\"].apply(str_to_float_array)\n",
    "        if \"nsd\" not in col_name:\n",
    "            df[\"trueArrowDirection\"] = df[\"trueArrowDirection\"].apply(str_to_float_array)\n",
    "            plotting.plot_mean_angular_error(df, \"Ground Truth Angular Error, \" + col_name, \"userID\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            plotting.plot_mean_angular_error(df, \"Ground Truth Angular Error, \" + col_name, \"imageURL\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        plotting.plot_mean_angular_agreement(df, \"Angular Agreement, \" + col_name)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
